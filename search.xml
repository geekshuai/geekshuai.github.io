<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[hexo下创建分类及实现hexo二级分类]]></title>
    <url>%2Fposts%2Fc4a19b3c.html</url>
    <content type="text"><![CDATA[hexo分类实现多子级划分下面会讲到如何创建分类,及使用二级分类功能!如果没有分类(categories)页面,就先创建一个1hexo new page categories进入新创建的页面目录1cd Hexo\source\categories编辑页面基本设置12345vim index.md#基本设置title: tagsdate: 2019-01-02 21:01:24type: "categories"如果设置了多说,畅言等评论会在分类或者标签什么的显示出来,如果不喜欢可以进行一下设置1234567vim index.md#基本设置title: tagsdate: 2019-01-02 21:01:24type: "categories"#加入此参数comments: false #代表关闭评论¶如何在文章中使用分类功能呢?创建一个新的markdown文档1hexo new "文章名称"生产后会提示你文件路径,一般在hexo/source/_posts下文章的基本设置123456789101112---title: CentOS7下Tomcat启动慢的原因及解决方案date: 2019-01-02 21:01:24comments: true #是否可评论toc: true #是否显示文章目录categories: #分类 - Linux运维tags: #标签 - centOS - tomcat---¶如何在文章中使用二级及多级分类呢?1234567891011121314---title: CentOS7下Tomcat启动慢的原因及解决方案date: 2019-01-02 21:01:24comments: true #是否可评论toc: true #是否显示文章目录categories: #分类 - Linux运维 #这是一级分类 - Python开发 #这是二级分类 - docker #这是三级分类 - xxxxxx #往下继续延伸就是无限子类划分tags: #标签 - centOS - tomcat---二级分类及多级分类图片演示]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo主题优化-文章置顶+置顶标签]]></title>
    <url>%2Fposts%2Fe574321.html</url>
    <content type="text"><![CDATA[博文置顶一种方法是手动对相关文件进行修改，具体可参考这篇文章。另一种方法就是，目前已经有修改后支持置顶的仓库，可以直接用以下命令安装。12npm uninstall hexo-generator-index --savenpm install hexo-generator-index-pin-top --save然后在需要置顶的文章的Front-matter中加上top: true即可。比如下面这篇文章：12345678910111213---title: Hexo主题优化-文章置顶+置顶标签comments: truetoc: truetop: true #再次添加此项即可categories: - hoxetags: - hoxedate: 2019-01-02 21:01:24---置顶功能已经可以实现了。置顶的文章显示在最上面之后，如果没有明确的置顶标志，是不是感觉很奇怪？设置置顶标志打开：/hexo/themes/next/layout/_macro目录下的post.swig文件，定位到&lt;div class=&quot;post-meta&quot;&gt;标签下，插入如下代码：1234567&#123;% if post.top %&#125; &lt;span class="post-meta-item-icon"&gt; &lt;i class="fa fa-thumb-tack"&gt;&lt;/i&gt; &lt;/span&gt; &lt;font color="red"&gt;置顶&lt;/font&gt; &lt;span class="post-meta-divider"&gt;|&lt;/span&gt; &#123;% endif %&#125;¶添加代码位置展示:¶页面展示:]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx配置文件-events配置部分(1.2)]]></title>
    <url>%2Fposts%2F1d10d4e6.html</url>
    <content type="text"><![CDATA[Nginx配置文件-events配置部分(1.2)此配置文件根据笔记本NGINX文章对比查看1worker_connections 1024;定义每个work_process同时开启的最大连接数，即允许最多只能有这么多连接。说明大小按照需求来设置,平常网站设置到1万就已经很好了!1accept_mutex on;当某一个时刻只有一个网络连接请求服务器时，服务器上有多个睡眠的进程会被同时叫醒，这样会损耗一定的服务器性能。Nginx中的accept_mutex设置为on，将会对多个Nginx进程（worker processer）接收连接时进行序列化，防止多个进程争抢资源。默认就是on。说明这里提到的进程是下图显示的worker process1multi_accept on;nginx worker processer可以做到同时接收多个新到达的网络连接，前提是把该参数设置为on。默认为off，即每个worker process一次只能接收一个新到达的网络连接。说明想要高并发就要把此参数设置成ON!1use epoll;Nginx服务器提供了多个事件驱动器模型来处理网络消息。其支持的类型有：select、poll、kqueue、epoll、rtsing、/dev/poll以及eventport。select：只能在Windows下使用，这个事件模型不建议在高负载的系统使用poll:Nginx默认首选，但不是在所有系统下都可用kqueue:这种方式在FreeBSD 4.1+, OpenBSD2.9+, NetBSD 2.0, 和 MacOS X系统中是最高效的epoll: 这种方式是在Linux 2.6+内核中最高效的方式rtsig:实时信号，可用在Linux 2.2.19的内核中，但不适用在高流量的系统中/dev/poll: Solaris 7 11/99+,HP/UX 11.22+, IRIX 6.5.15+, and Tru64 UNIX 5.1A+操作系统最高效的方式eventport: Solaris 10最高效的方式¶为什么Nginx总体性能比Apache高说明Nginx使用epoll和kqueue(freebsd)异步网络I/O模型apache使用传统的select模型¶使用通俗的语言比喻epoll和select模型假设你在大学读书,住的宿舍楼有很多房间,你的朋友要来找你。select版宿管大妈就会带着你的朋友到各房间挨个去找,直到找到你为止。而epoll版宿管大妈会先记下每位入住同学的房间号,你的朋友来找你时,只需告诉你的朋友你住在哪个房间即可,不用亲自带着你的朋友满宿舍楼找人了。如果同时来了100个人,都要找自己住这栋楼的同学, select版和epo版宿管大妈,谁的效率更高,就很明显了。¶在实际工作中如何选择合适的服务软件静态业务：高并发场景尽量采用nginx或者lighttpd，二者首选nginx动态服务：理论上采用nginx和apache均可，建议选择nginx，为了避免相同业务的服务软件多样化，增加额外维护成本，动态业务可以由nginx前端代理，再根据页面元素的类型目录，转发到后端相应的服务器处理进程。既有静态业务也有动态业务：采用nginx]]></content>
      <categories>
        <category>Web服务</category>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx配置文件-server配置部分(1.4)]]></title>
    <url>%2Fposts%2F1d10d4e6.html</url>
    <content type="text"><![CDATA[nginx配置文件-server配置部分(1.4)server{} 包含在http{}内部，每一个server{}都是一个虚拟主机（站点）。¶以下为nginx.conf配置文件中server{}部分的内容。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081 server &#123; listen 80; //监听端口为80，可以自定义其他端口，也可以加上IP地址，如，listen 127.0.0.1:8080; server_name localhost; //定义网站域名，可以写多个，用空格分隔。 #charset koi8-r; //定义网站的字符集，一般不设置，而是在网页代码中设置。 #access_log logs/host.access.log main; //定义访问日志，可以针对每一个server（即每一个站点）设置它们自己的访问日志。 ##在server&#123;&#125;里有很多location配置段 location / &#123; root html; //定义网站根目录，目录可以是相对路径也可以是绝对路径。 index index.html index.htm; //定义站点的默认页。 &#125; #error_page 404 /404.html; //定义404页面 # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; //当状态码为500、502、503、504时，则访问50x.html location = /50x.html &#123; root html; //定义50x.html所在路径 &#125; # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #定义访问php脚本时，将会执行本location&#123;&#125;部分指令 #location ~ \.php$ &#123; # proxy_pass http://127.0.0.1; //proxy_pass后面指定要访问的url链接，用proxy_pass实现代理。 #&#125; # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \.php$ &#123; # root html; # fastcgi_pass 127.0.0.1:9000; //定义FastCGI服务器监听端口与地址，支持两种形式，1 IP:Port， 2 unix:/path/to/sockt # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; //定义SCRIPT_FILENAME变量，后面的路径/scripts为上面的root指定的目录 # include fastcgi_params; //引用prefix/conf/fastcgi_params文件，该文件定义了fastcgi相关的变量 #&#125; # deny access to .htaccess files, if Apache's document root # concurs with nginx's one # #location ~ /\.ht &#123; //访问的url中，以/.ht开头的，如，www.example.com/.htaccess，会被拒绝，返回403状态码。 # deny all; //这里的all指的是所有的请求。 #&#125;&#125;# another virtual host using mix of IP-, name-, and port-based configuration##server &#123;# listen 8000; //监听8000端口# listen somename:8080; //指定ip:port# server_name somename alias another.alias; //指定多个server_name# location / &#123;# root html;# index index.html index.htm;# &#125;#&#125;# HTTPS server##server &#123;# listen 443 ssl; //监听443端口，即ssl# server_name localhost;### 以下为ssl相关配置# ssl_certificate cert.pem; //指定pem文件路径# ssl_certificate_key cert.key; //指定key文件路径# ssl_session_cache shared:SSL:1m; //指定session cache大小# ssl_session_timeout 5m; //指定session超时时间# ssl_protocols TLSv1 TLSv1.1 TLSv1.2; //指定ssl协议# ssl_ciphers HIGH:!aNULL:!MD5; //指定ssl算法# ssl_prefer_server_ciphers on; //优先采取服务器算法# location / &#123;# root html;# index index.html index.htm;# &#125;#&#125;]]></content>
      <categories>
        <category>Web服务</category>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx配置文件-http配置部分(1.3)]]></title>
    <url>%2Fposts%2F1d10d4e6.html</url>
    <content type="text"><![CDATA[Nginx配置文件-http配置部分(1.3)官方文档 http://nginx.org/en/docs/参考链接： https://segmentfault.com/a/1190000012672431参考链接： https://segmentfault.com/a/1190000002797601参考链接：http的header https://kb.cnblogs.com/page/92320/MIME-Type1MIME-Typeinclude mime.types; //cat conf/mime.types定义nginx能识别的网络资源媒体类型（如，文本、html、js、css、流媒体等）default_type application/octet-stream;定义默认的type，如果不定义改行，默认为text/plain.说明这些定义的类型可以在通目录下nginx/conf/mime.types中查看到!log_format12345log_formatlog_format main '$remote_addr - $remote_user [$time_local] "$request" ' '$status $body_bytes_sent "$http_referer" ' '"$http_user_agent" "$http_x_forwarded_for"';其中main为日志格式的名字，后面的为nginx的内部变量组成的一串字符串。access_log logs1access_log logs/access.log main;定义日志的路径以及采用的日志格式，该参数可以在server配置块中定义。sendfile12sendfile on;`是否调用sendfile函数传输文件，默认为off，使用sendfile函数传输，可以减少user mode和kernel mode的切换，从而提升服务器性能。对于普通应用设为 on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理速度，降低系统的负载。sendfile_max_chunk1sendfile_max_chunk 128k;该参数限定Nginx worker process每次调用sendfile()函数传输数据的最大值，默认值为0，如果设置为0则无限制。tcp_nopush1tcp_nopush on;当tcp_nopush设置为on时，会调用tcp_cork方法进行数据传输。使用该方法会产生这样的效果：当应用程序产生数据时，内核不会立马封装包，而是当数据量积累到一定量时才会封装，然后传输。这样有助于解决网络堵塞问题。默认值为on。举例：快递员收快递、发快递，包裹累积到一定量才会发，节省运输成本。keepalive_timeout1keepalive_timeout 65 60;该参数有两个值，第一个值设置nginx服务器与客户端会话结束后仍旧保持连接的最长时间，单位是秒，默认为75s。第二个值可以省略，它是针对客户端的浏览器来设置的，可以通过curl -I看到header信息中有一项Keep-Alive: timeout=60，如果不设置就没有这一项。第二个数值设置后，浏览器就会根据这个数值决定何时主动关闭连接，Nginx服务器就不操心了。但有的浏览器并不认可该参数。send_timeout1send_timeout这个超时时间是发送响应的超时时间，即Nginx服务器向客户端发送了数据包，但客户端一直没有去接收这个数据包。如果某个连接超过send_timeout定义的超时时间，那么Nginx将会关闭这个连接。client_max_body_size1client_max_body_size 10m;浏览器在发送含有较大HTTP包体的请求时，其头部会有一个Content-Length字段，client_max_body_size是用来限制Content-Length所示值的大小的。这个限制包体的配置不用等Nginx接收完所有的HTTP包体，就可以告诉用户请求过大不被接受。会返回413状态码。例如，用户试图上传一个1GB的文件，Nginx在收完包头后，发现Content-Length超过client_max_body_size定义的值，就直接发送413(Request Entity Too Large)响应给客户端。gzip1gzip on；是否开启gzip压缩。gzip_min_length1gzip_min_length 1k;设置允许压缩的页面最小字节数，页面字节数从header头得content-length中进行获取。默认值是20。建议设置成大于1k的字节数，小于1k可能会越压越大。gzip_buffers1gzip_buffers 4 16k;设置系统获取几个单位的buffer用于存储gzip的压缩结果数据流。4 16k代表分配4个16k的buffer。gzip_http_version1gzip_http_version 1.1;用于识别 http 协议的版本，早期的浏览器不支持 Gzip 压缩，用户会看到乱码，所以为了支持前期版本加上了这个选项。如果你用了Nginx反向代理并期望也启用Gzip压缩的话，由于末端通信是http/1.1，故请设置为 1.1。gzip_comp_level1gzip_comp_level 6;gzip压缩比，1压缩比最小处理速度最快，9压缩比最大但处理速度最慢(传输快但比较消耗cpu)gzip_types mime-type1gzip_types mime-type ... ;匹配mime类型进行压缩，无论是否指定,”text/html”类型总是会被压缩的。在conf/mime.conf里查看对应的type。示例：gzip_types text/plain application/x-javascript text/css text/html application/xml;gzip_proxied1gzip_proxied any;Nginx作为反向代理的时候启用，决定开启或者关闭后端服务器返回的结果是否压缩，匹配的前提是后端服务器必须要返回包含”Via”的 header头。以下为可用的值：off - 关闭所有的代理结果数据的压缩expired - 启用压缩，如果header头中包含 “Expires” 头信息no-cache - 启用压缩，如果header头中包含 “Cache-Control:no-cache” 头信息no-store - 启用压缩，如果header头中包含 “Cache-Control:no-store” 头信息private - 启用压缩，如果header头中包含 “Cache-Control:private” 头信息no_last_modified - 启用压缩,如果header头中不包含 “Last-Modified” 头信息no_etag - 启用压缩 ,如果header头中不包含 “ETag” 头信息auth - 启用压缩 , 如果header头中包含 “Authorization” 头信息any - 无条件启用压缩gzip_vary1gzip_vary on；和http头有关系，会在响应头加个 Vary: Accept-Encoding ，可以让前端的缓存服务器缓存经过gzip压缩的页面，例如，用Squid缓存经过Nginx压缩的数据。]]></content>
      <categories>
        <category>Web服务</category>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx配置文件-nginx.conf全局配置(1.1)]]></title>
    <url>%2Fposts%2F1d10d4e6.html</url>
    <content type="text"><![CDATA[nginx.conf全局配置(1.1)此文件结合笔记本上的NGINX文章查看1user nobody;定义运行nginx服务的用户,还可以加上组,如 user nobody nobody;1worker_processes 1;定义nginx子进程数量，即提供服务的进程数量，该数值建议和服务cpu核数保持一致。除了可以定义数字外，还可以定义为auto，表示让系统自动调整。1error_log logs/error.log;定义错误日志的路径，可以是相对路径（相对prefix路径的），也可以是绝对路径。该配置可以在此处定义，也可以定义到http、server、location里1error_log logs/error.log notice;定义错误日志路径以及日志级别.错误日志级别：常见的错误日志级别有[debug|info|notice|warn|error|crit|alert|emerg]，级别越高记录的信息越少。如果不定义默认是error1pid logs/nginx.pid;定义nginx进程pid文件所在路径，可以是相对路径，也可以是绝对路径。1worker_rlimit_nofile 100000;定义nginx最多打开文件数限制。如果没设置的话，这个值为操作系统（ulimit -n）的限制保持一致。把这个值设高，nginx就不会有“too many open files”问题了。]]></content>
      <categories>
        <category>Web服务</category>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用户访问web网站基本流程]]></title>
    <url>%2Fposts%2Ffb1665c6.html</url>
    <content type="text"><![CDATA[用户访问网站基本流程第一步客户端在浏览器输入www.geekshuai.com网址,回车后,系统首先查找系统本地的DNS缓存及hosts文件信息,确认是否存在www.geekshuai.com域名对应的IP解析记录,如果有就直接获取IP地址信息,然后去访问这个地址,一般第一次访问的时候,是没有缓存DNS解析记录的,而且hosts文件多半部分是内部测试使用的也不会存在网址的缓存记录第二步上面的步骤没有找到www.geekshuai.com域名对应的解析记录的话,系统会把浏览器的解析请求发送给客户端本地设置的DNS服务器(通常称此DNS为LDNS,即local DNS)解析,如果LDNS服务器的本地缓存有对应的接续记录就只会返回IP地址给客户端,如果没有LDNS服务器会负责请求其他的DNS服务器,第三步LDNS从DNS系统的(&quot; . &quot;)根开始请求对www.geekshuai.com域名的解析,并针对各层级的DNS服务器进行一系列的查找,最终会查找到geekshuai.com域名对应的授权DNS服务器,而这个授权DNS服务器正是企业购买域名时用于管理域名解析的服务器,这个授权服务器会有www.geekshuai.com对应的UO解析记录,如果没有IP解析记录就表明没有这个网站,或者是域名管理人员没有对www.geekshuai.com域名做域名解析,即网站没有架设好!第四步geekshuai.com域名的授权DNS服务器会把www.geekshuai.com对应的最终IP解析记录(如:10.0.0.1)发给LDNS第五步LDNS把来自授权DNS服务器www.geekshuai.com对应的IP解析记录发给客户端浏览器,并且会把该域名和IP的对应解析缓存起来(下次可以直接返还给客户端浏览器)这些缓存记录在指定时间(DNS TTL值控制)内不会过期TTL 说明一些门户网站一般设置为30秒,时间越长代表更新时间越长,在更新的时候会等待各级DNS服务器的缓存都失效再更新第六步客户端浏览器获取到了www.geekshuai.com对应的IP地址,接下来,浏览器会请求获得IP地址对应的网站服务器,网站服务器接收到客户的请求并响应处理(此处的处理可能一一台云主机,也可能是成百上千台集群服务器),网站服务器将内容返还给客户端浏览器.至此,一次访问浏览网页的完整过程就结束了!¶提示上面说到的仅仅是客户端用户第一次访问网站的基本过程,连续访问后,系统本地和LDNS层级都会有缓存记录,再访问时流程会有些变化,会直接取本地缓存记录,这样访问过程就很快了!]]></content>
      <categories>
        <category>计算机理论</category>
        <category>http/https</category>
      </categories>
      <tags>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[树莓派root账号开启]]></title>
    <url>%2Fposts%2F14aa896.html</url>
    <content type="text"><![CDATA[ROOT账号开启很多小伙伴在使用树莓派的时候只能使用普通用户+sudo的方式进行输入执行命令,没有办法直接sudo su - root切换到root超级管理员账号上去,这是因为ROOT密码：Raspbian 系统默认未开启，需要自行开启并设置密码。¶方法如下第一步使用pi用户登录树莓派系统之后，在命令行下输入：1sudo passwdroot然后提示你输入两次要设置的密码第二步最后执行如下命令：1sudo passwd --unlock root #解锁root用户至此，root账户开启并设置好密码了。]]></content>
      <categories>
        <category>树莓派</category>
      </categories>
      <tags>
        <tag>树莓派</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[10分钟带你了解一致性hash算法]]></title>
    <url>%2Fposts%2F14aa896.html</url>
    <content type="text"><![CDATA[10分钟带你了解一致性hash算法一致性hash算法¶环境描述在了解hash算法之前先去了解一下缓存中的一个应用场景，再来理解一致性hash算法就会简单很多。¶场景描述假设，公司有三台缓存服务器，用于缓存图片，这三台缓存服务器的编号为0号，1号，2号，现在有三万张图片需要缓存，希望这么多的缓存数据能均匀的缓存到3台服务请求上去(也就是说每台机器上平均分配1万左右的数据)，以便能够分摊缓存的压力。此处的问题：那么应该怎么做？如果我们没有任何规律的将3万张图片平均的缓存到3台服务器上，可不可以满足需求？答案：可以！但是如果这么做，当我们需要访问某个和缓存选项时，则需要遍历3台服务器，从这3万个缓存项中找到需要访问的缓存，整个遍历下来的过程时间长，效率低，这样也就失去了缓存存在的价值和意义，缓存存在的目的就是提高速度，改善用户的体验，减轻后端服务器的压力，如果每次都要遍历整个缓存集群服务器，不用想都能累死.好一点的做法：原始的做法是对缓存项的键进行hash，将hash后的结果对缓存服务器数量进行取模操作，通过取模后结果，决定缓存项要缓存在那一台服务器上，举例说明：假设以我们使用的图片名称作为访问图片的key，假设图片名称不能重复，那么我们可以使用以下公式，及计算出图片应该存放在那台服务器上。公式：hash（图片名称）% N因为图片名称是不能重复的，所以，当我们对同一个图片名称做相同的hash运算时得出的结果应该是不变的，如果有3台服务器，使用hash运算后的结果对3取余，那么余数也一定是0、1、2，正号跟之前服务器编号相同，如果求余的结果为1，就把图片名称对应的图片缓存在1号服务器上，2就和缓存到2号服务器上，那么当我们访问任意一个图片的时候，只要再次对图片名称进行运算即可得出对应的图片应该被放在那台缓存服务器上，只需要去对应的服务器上去查找即可，如果图片在对应的服务器上不存在，证明没有被缓存(接着会把这张图片缓存在这个服务器上)，也不用再去遍历其他缓存服务器了。通过此方法可以把3万图片随机分布到3台缓存服务器上，下次访问某张图片时，直接能够判断出该图片应该存放在那台缓存服务器上了。可以把上述算法称为：HASH算法还活着是取模算法¶以下是运算原理图：但是使用上述hash算法进行缓存时会出现一些缺陷，如果3台并不能满足我们的需求时那么应该怎么做?肯定是增加几台服务器就可以了，假设我们增加1台服务器，服务器的数量由3变成了4，此时仍然用上述方法对同一张图片进行缓存，那么这张图片所在的服务器的编号必定是与原来的3台服务器所在的 编号是不同的，因为除数3变成了4，被除数不变的情况下，余数肯定不同，这情况带来的结果就是当服务器数量变动时，所有和缓存的位置都要发生改变，也就是说缓存服务器数量发生改变时，所有缓存数据在一定时间是失效的，当应用无法从缓存中和获取数据时，则会向后端服务器请求数据，同理，如果3台缓存服务器中突然有一台出现了故障，，无法进行缓存数据，那么需要移除故障机器，但是如果移除了一台缓存服务器后，数量从3变成了2，如果想访问有一张图片，这张图片缓存为位置必定发生改变，以前缓存的图片也会失去缓存的作用和意义，由于==**`大量缓存在同一时间失效，造成了缓存的雪崩(血崩)，此时前端缓存已经无法起到成端部分压力的作用，后端服务器将会承担所有巨大压力，会导致整个系统可能会被压垮，==所以为了避免这类情况的发生，一致性hash算法诞生了！综合一下上述出现的问题：第一个问题：当缓存服务器数量发生变化时，会引起缓存的血崩，可能引起整体系统压力过大而崩溃（大量缓存同一时间失效），第二个问题：当缓存服务器数量发生变化时，几乎所有缓存的数据都会发生改变，怎么才能尽量减少受影响的缓存？¶一致性hash算法概念其实一致性hash算法也是取模运算，只是，上面描述的取模算法是对服务器数量进行取模，而一致性hash是对2^32取模插入小知识：为什么非得对2^32取余？对232取余是有依据的IPV4最大数量就是232，所以这样就能保证所有的ip的地址进行取余时不会重复—对应hash环上面的正数。首先把2^32想象成有一个大大的圆，就像钟表上由60个点组成的圆，如图：由2^32个点组成的圆环称为hash环。圆环的正上方代表0，0点右侧第一个1以此类推2,3,4,5,6……一直到最后2^32-1。假设我们有3台缓存服务器，服务器A，B，C，然后用他们各自的IP地址进行hash计算，使用hash后的结果改过对2^32取模。hash(服务器A的IP地址) % 2^32通过上面的计算结果一定是一个0到232-1之间的一个整数，我们就用这个整数代表服务器A，既然这个整数肯定处于0到232-1之间，那么必定与hash环的上一个点与这个整数对应。刚才已经说明，使用这个整数代表服务器A，那么服务器A就可以映射到这个环上。同理服务器B和C也是相同的方法映射到hash环中计算公式：hash(服务器B的IP地址) % 2^32hash(服务器C的IP地址) % 2^32算出结果然后将服务器映射到hash环上去。如图所示：假设3台服务器均匀到映射到hash环上，(这是理想得到情况)假设，我们需要使用缓存服务器缓存图片而且仍然使用图片的名称作为找到图片的Key，那么我们使用以下公式可以将图片映射到上图中的hash环上。hash(图片名称) % 2^32映射后得到的结果如下图：(红点点代表图片)那么问题来了，图片和服务器都被映射到了hash环上，那么上图的图片到底应该缓存到那一台缓存服务器上呢？答：应该被缓存到A服务器上，为什么？因为从图片开始的位置开始，沿着顺时针方向遇到的第一个服务器就是A服务器，所以会被缓存到A服务器上。如下图：一致性hash算法说明：通过一致性hash算法这种方法，判断一个对象应该被缓存到那台服务器上的，将缓存服务器与被缓存对象都映射到hash环上以后，从被缓存对象的位置出发，沿着顺时针方向遇到的第一个服务器，就是当前对象将要缓存的服务器，由于被缓存对象与服务器hash后的值都是固定的，所以服务器不变的情况下，一张图片必定会被缓存到固定的服务器上，那么，当下次访问这张图片时，只要再次使用相同的算法进行计算，即可算出这张图片被缓存在那个服务器上，直接去对应的服务器上查找即可。假设有4张图片需要缓存，如下图：1、2图片缓存到A上，3缓存到B上，4缓存到C¶一致性hash算法的优点一致性hash算法能够解决之前出现的问题吗？如果进行简单的取模，当服务器数量发生变化时，会产生缓存的雪崩，从而导致系统崩溃，那么用一致性hash能够避免这个问题吗？继续模拟测试实验！！假设服务器B出现故障，需要移除B，如下图：在服务器B没有移除时，图片3应该缓存到B中，可是移除后，按照一致性hash算法是规则，3应该被缓存到C中，因为从3的位置顺时针除法遇到的第一个服务器节点是C，也就是说如果B出现故障移除后，3的缓存位置发生改变。这里的一致性hash算法的优点就体现出来了！图片4依然会被缓存到C中，图片1和2突然缓存到A中，与移除B之前没有任何区别，这就是优点！1）如果使用hash算法：当服务器数量发生改变时，所有的服务器缓存在同一时间失效了2）而使用一致性hash算法：服务器数量发生改变时，并不是所有都会失效，而只有部分缓存失效，前端的缓存仍然能分担整个系统的压力，而不至于所有压力都在同一个时间集中到后端服务器上。¶hash环偏斜问题在最开始介绍概念年的时候，说的是在理想的情况下是**均匀的分布到hash环上！**如下图但是理想是很丰满的，我们想象的和现实往往是不同的！在实际映射中，服务器可能会被映射成一下模样那么被缓存的对象很有可能大部分集中缓存到某一台服务器上如下图:图上2、3、4、5、6、都很会存储到A服务器上，1会存到B上，C服务器一张也没有，三台服务器并没有合理的平均充分的利用，缓存分布极度不均匀，重要的是如果A出现故障，会导致失效的数量也将达到最大值。在极端的情况下依然会出现系统崩溃的问题！以上情况被称之为hash环偏斜，那么如何防止hash环偏斜呢？¶虚拟节点“虚拟节点”是“实际节点”(实际的物理服务器)在hash环上的复制品，一个实际节点可以对应多个虚拟节点。如下图：ABC三台服务分别虚拟出一个虚拟节点（也可以虚拟出更多的虚拟节点）引入虚拟节点的概念后，缓存的分布就均衡的多了，上图中3、4、5、的图片都被放到了节点A中如果不放心可以虚拟出更多的虚拟节点，以便减少hash环偏斜所带来的影响，虚拟节点越多，hash环上的节点就越多，缓存均匀分布的概率就越大！！！]]></content>
      <categories>
        <category>计算机理论</category>
        <category>hash</category>
      </categories>
      <tags>
        <tag>hash</tag>
      </tags>
  </entry>
</search>
